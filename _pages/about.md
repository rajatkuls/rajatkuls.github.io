---
permalink: /
title: "Rajat Kulshreshtha"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am an Applied Scientist on the AGI Foundations team at Amazon building multimodal, real-time foundation models used across Amazon experiences. My team leads efforts in multimodal speech–language capabilities, specifically in post-training, data, and inference efficiency workstreams. I have also built and maintained on-device evaluation and release pipelines, with a focus on making large models responsive, reliable, and practical in production.

I have 7+ years of AI research and engineering experience. Previously, I was a founding engineer at Telling.ai, where I built speech-first AI systems for longitudinal respiratory health monitoring (e.g. COPD) and co-authored journal publications and patents.

I hold a research master’s degree in Language Technologies from Carnegie Mellon University and a bachelor’s degree in Electronics & Electrical Engineering (with a CS minor) from IIT Guwahati.

In my free time, I enjoy vibe coding my ideas to see how far LLMs can be pushed on new problems. Check out my recent project [LLM Powered After Visit Summary](https://eyekapoor.com) that was selected for a panel discussion at the American Academy of Ophthalmology.

I’m best reached at rk [dot] kuls [at] [gmail]. More details are in my [CV](/files/cv.pdf). A full list of my publications can be found [here]({{ '/publications/' | relative_url }}) and on [Google Scholar](https://scholar.google.com/citations?user=WM92KKkAAAAJ).


